{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "daebb557-89d2-4d96-a6df-b21a91add59a",
   "metadata": {},
   "source": [
    "This Notebook is for analyzing profile test data. The test data includes 20 json files. This notebook will load the data into dataframe and analyzed using Spark SQL."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2cc345a-4932-49b0-9946-472ebeaa94b7",
   "metadata": {},
   "source": [
    "1. Import PySpark Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "839a1e07-9d85-478c-865c-75af1a28bfe6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56d652a-2cdc-4077-8746-dc6bd2279cce",
   "metadata": {},
   "source": [
    "2. Create SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "149fcb76-3e58-4fdc-8dfd-4bfcf4d20e64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Profile Analyse\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90298e6e-52a8-4940-8681-6d32d2281879",
   "metadata": {},
   "source": [
    "3. Load JSON FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9701f2a-ca45-4050-ba09-80624f0d48c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = spark.read.json(\"test_data/*.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de33a987-8e13-455d-9142-e8c3b79f34bd",
   "metadata": {},
   "source": [
    "4. Print DataFrame Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0403451-1711-46ee-9cec-5404340cec62",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- profile: struct (nullable = true)\n",
      " |    |-- firstName: string (nullable = true)\n",
      " |    |-- jobHistory: array (nullable = true)\n",
      " |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |-- fromDate: string (nullable = true)\n",
      " |    |    |    |-- location: string (nullable = true)\n",
      " |    |    |    |-- salary: long (nullable = true)\n",
      " |    |    |    |-- title: string (nullable = true)\n",
      " |    |    |    |-- toDate: string (nullable = true)\n",
      " |    |-- lastName: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5db572-b8e5-4327-b153-d799b9bcaaf1",
   "metadata": {},
   "source": [
    "5. Records in DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecc3791b-94d4-425e-94e7-2c93223b89bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17139693"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e581ee2d-64fe-491b-ae55-198f511c34cc",
   "metadata": {},
   "source": [
    "6. Flatten Nested DataFrame (Data Preparation for Analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75db769c-83d9-4fc0-8432-3de300c82f27",
   "metadata": {},
   "source": [
    "Firstly, convert firstName, lastName and jobHistory into columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14ffdb73-b7ab-4c59-a631-0f38f5684de1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nested_df = df.select(\"id\", \"profile.firstName\", \"profile.lastName\", \"profile.jobHistory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1393143c-8094-4390-9bbf-aec006d050ab",
   "metadata": {},
   "source": [
    "Secondly, use explode function to explode jobHistory array into multiple rows. Noted: if jobHistory is empty Array, there will be no records in the exploded dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "765b58f7-4d17-4cb3-9099-08e454ef527d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import explode\n",
    "exploded_df = nested_df.withColumn(\"jobHistory\", explode(nested_df.jobHistory))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2405e6a-26a0-4445-9853-60deca9cb559",
   "metadata": {},
   "source": [
    "Thirdly, convert fromDate, location, salary, title, toDate into columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbd1e223-0cc6-4569-b925-2e078be5d4ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "flattern_df = exploded_df.select(\"id\", \"firstName\", \"lastName\", \"jobHistory.fromDate\", \"jobHistory.location\", \"jobHistory.salary\", \"jobHistory.title\", \"jobHistory.toDate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7956d61-7fc1-4db7-a63e-532972cacdba",
   "metadata": {
    "tags": []
   },
   "source": [
    "7. Create TempView for dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58e15ec1-d979-4521-8809-c7f1623ad12f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "flattern_df.createOrReplaceTempView(\"people\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc741fd-ef4c-41cb-83cf-9b58df6ef538",
   "metadata": {},
   "source": [
    "8. Average Salary for each profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4321f111-f3a6-4ef7-a7cc-073a838d7275",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+--------+------------------+\n",
      "|                  id|firstName|lastName|         avgSalary|\n",
      "+--------------------+---------+--------+------------------+\n",
      "|82dab74c-3946-45b...|   Robert|  Zywiec| 66833.33333333333|\n",
      "|5894afab-574f-429...|  Richard|  Zywiec|           69625.0|\n",
      "|ba24222d-6e39-40d...|  Matthew|  Zywiec|           65500.0|\n",
      "|58305fc8-a83c-4f2...|    Joyce| Zywicki|          123500.0|\n",
      "|6cdb8e48-ee18-4b4...|     Jodi| Zywicki|138571.42857142858|\n",
      "|13348815-753b-43d...|Stephanie| Zywicki|131888.88888888888|\n",
      "|080d601f-774b-47f...| Jonathan| Zywicki|          120625.0|\n",
      "|3462e81b-a9cc-4ac...|   Sandra| Zywicki|43333.333333333336|\n",
      "|b8a6bf60-03da-4e0...|     Paul| Zywicki| 98166.66666666667|\n",
      "|eeb15ed5-fb0d-4d6...|    Donna| Zywicki|          115000.0|\n",
      "+--------------------+---------+--------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlDF = spark.sql(\"SELECT id, firstName, lastName, avg(salary) as avgSalary FROM people group by id, firstName, lastName order by lastName desc limit 10\")\n",
    "sqlDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46b48a6-df44-435f-a1b4-fd4e33ac0c58",
   "metadata": {},
   "source": [
    "9. Average Salary for whole DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "986a2e70-8580-4b6f-8fb5-3ff7d1356bb9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|       avgSalary|\n",
      "+----------------+\n",
      "|97473.6229416272|\n",
      "+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlDF = spark.sql(\"SELECT avg(salary) as avgSalary FROM people\")\n",
    "sqlDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb08752-c89c-4d32-946f-8ea051178395",
   "metadata": {},
   "source": [
    "10. Top 5 Paying Job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7916cdac-9b1a-4412-ace3-f343922fc42f",
   "metadata": {},
   "source": [
    "If we consider the most paying job contury wide, the average pay of a job is calculated based on all the jobs accorss all locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b54b6945-7bf1-4a4b-8ee2-4e448f937d07",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------+\n",
      "|               title|        avgSalary|\n",
      "+--------------------+-----------------+\n",
      "|      internal sales|97555.94285236429|\n",
      "|  service technician| 97539.8681255395|\n",
      "|     Support Analyst|97515.95270974559|\n",
      "|clinical psycholo...|97515.49312935937|\n",
      "|             dentist| 97515.0922739562|\n",
      "+--------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlDF = spark.sql(\"SELECT title, avg(salary) as avgSalary FROM people group by title order by avgSalary desc, title limit 5\")\n",
    "sqlDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0083bdb9-f5ed-4211-85a0-ee027fece6ad",
   "metadata": {},
   "source": [
    "If we consider the most paying job location wide, the average pay of a job is calculated based on all the jobs in a specific location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac02d77e-c0c3-4c79-946e-6cbeed3cf4c1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+-----------------+\n",
      "|               title| location|        avgSalary|\n",
      "+--------------------+---------+-----------------+\n",
      "|   cosmetic injector|Melbourne|97685.17451749711|\n",
      "|safety superinten...|    Perth|97670.41450212519|\n",
      "|  Multi Site Manager|Melbourne| 97646.6894018173|\n",
      "|             trimmer| Brisbane|97643.56431163519|\n",
      "|       store manager|   Hobart|97641.65395372489|\n",
      "+--------------------+---------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlDF = spark.sql(\"SELECT title, location, avg(salary) as avgSalary FROM people group by title, location order by avgSalary desc, title, location limit 5\")\n",
    "sqlDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32fa515-0ab9-40b5-b3fa-8cb67c7ab64e",
   "metadata": {},
   "source": [
    "11. Bottom 5 Paying Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c015672-cea2-48dc-bcf0-303bc1dc0892",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------+\n",
      "|               title|        avgSalary|\n",
      "+--------------------+-----------------+\n",
      "|business developm...|97410.55035168272|\n",
      "|    research analyst|97412.92759450486|\n",
      "|retail sales cons...|97419.07190129737|\n",
      "|Administration Of...|97423.83029048711|\n",
      "|           paralegal|97432.43600056692|\n",
      "+--------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlDF = spark.sql(\"SELECT title, avg(salary) as avgSalary FROM people group by title order by avgSalary, title limit 5\")\n",
    "sqlDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592c6150-ce74-4743-ac85-6874b20a7e82",
   "metadata": {},
   "source": [
    "12. The person that makes most money"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0a81de-2213-4821-9369-09f0615baff0",
   "metadata": {},
   "source": [
    "To find the person that makes most money currently, we need to make sure the person is still working (toDate is null) and then find the highest salary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5483fcf-6299-424e-a774-08006438c225",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+--------+------+\n",
      "|                  id|firstName|lastName|salary|\n",
      "+--------------------+---------+--------+------+\n",
      "|5b217f27-8f8d-4dc...|    Kevin|    Zyla|159000|\n",
      "+--------------------+---------+--------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlDF = spark.sql(\"\"\" SELECT id, firstName, lastName, salary FROM people where toDate is null order by salary desc, lastName desc, fromDate desc limit 1   \"\"\")\n",
    "sqlDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1156f86a-59b2-400a-8ef0-54e46b7e70e0",
   "metadata": {},
   "source": [
    "13. Most popular tilte in 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64429882-6c76-4f87-8226-cd4fc9916ed8",
   "metadata": {},
   "source": [
    "To Find most popular title started in 2019, we need to extract year from fromDate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c07f5ac-b107-4da8-862b-9905a38fbc6b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|   MostPopularJob|\n",
      "+-----------------+\n",
      "|Sheetmetal Worker|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlDF = spark.sql(\"\"\" select title as MostPopularJob from ( SELECT title, count(*) as con  FROM people where SUBSTRING(fromDate, 1, 4) = '2019' group by title order by con desc limit 1) \"\"\")\n",
    "sqlDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5174bda2-2f34-4ac0-8661-92f5b8fadbf8",
   "metadata": {},
   "source": [
    "14. How many people are currently working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca46bb1d-c6a7-440e-8383-1028ac80bfa9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|NumOfWorkingPeople|\n",
      "+------------------+\n",
      "|           7710613|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlDF = spark.sql(\"\"\" SELECT count(distinct id) as NumOfWorkingPeople FROM people where toDate is null \"\"\")\n",
    "sqlDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c71c98-e52c-4b41-b1ba-7e7a61e36b79",
   "metadata": {},
   "source": [
    "15. List latest job for each profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "79568b72-b745-4869-8bbd-567e6978513c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+--------+---------+--------------------+------+----------+----------+\n",
      "|                  id|firstName|lastName| location|               title|salary|  fromDate|    toDate|\n",
      "+--------------------+---------+--------+---------+--------------------+------+----------+----------+\n",
      "|ba24222d-6e39-40d...|  Matthew|  Zywiec|    Perth|  Multi Site Manager| 67000|2017-04-23|      null|\n",
      "|5894afab-574f-429...|  Richard|  Zywiec|   Sydney|           assembler| 83000|2018-07-23|      null|\n",
      "|82dab74c-3946-45b...|   Robert|  Zywiec| Adelaide|registration officer| 85000|2016-08-08|2019-04-08|\n",
      "|4e26c80a-8e84-46f...|    Bobby| Zywicki|    Perth| taxation accountant| 89000|2017-12-11|2019-04-11|\n",
      "|f643f39c-e18a-430...|   Calvin| Zywicki| Adelaide|assistant operati...|144000|2015-04-24|2019-01-24|\n",
      "|03aeca24-7be1-42a...|  Charles| Zywicki|   Sydney|    sales consultant| 95000|2016-06-10|2019-04-10|\n",
      "|cc529ff4-2dbf-4ce...|  Cherryl| Zywicki|    Perth|             trimmer| 66000|2017-06-01|2019-04-01|\n",
      "|296999c2-8951-405...|Christine| Zywicki|Melbourne|      internal sales| 71000|2018-09-16|2019-01-16|\n",
      "|f16672c0-424c-48c...|  Darlene| Zywicki| Adelaide|           evaluator| 76000|2014-02-23|2019-02-23|\n",
      "|eeb15ed5-fb0d-4d6...|    Donna| Zywicki| Brisbane|      internal sales|115000|2019-01-23|      null|\n",
      "+--------------------+---------+--------+---------+--------------------+------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlDF = spark.sql(\"\"\" SELECT id, firstName, lastName, location, title, salary, fromDate, toDate from (SELECT *, \n",
    "ROW_NUMBER() OVER(PARTITION BY id ORDER BY fromDate DESC) AS row_number FROM people) where row_number = 1 order by lastName desc, firstName  limit 10 \"\"\")\n",
    "sqlDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b8359b-4ab5-4435-a0ac-9dc4d106ae29",
   "metadata": {},
   "source": [
    "16. Highest Paying job for each profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5f137d45-c7e3-4f48-be2e-ad840a33be77",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+--------------------+---------+--------+------+--------+\n",
      "|               title| location|                  id|firstName|lastName|salary|yearMade|\n",
      "+--------------------+---------+--------------------+---------+--------+------+--------+\n",
      "|           evaluator|Melbourne|00008a82-3345-419...|     Alan| Hawkins| 87000|    2016|\n",
      "|     devops engineer| Adelaide|00008d2e-3760-452...|   Alfred|     Siu| 61000|    2015|\n",
      "|  service technician| Adelaide|0000aa9b-7c17-489...|     Juan|    Moss| 85000|    2018|\n",
      "|     Support Analyst| Adelaide|0000b622-2709-4ef...|     Mark|     Roy| 83000|    2018|\n",
      "|     counter manager| Brisbane|0000c8c2-af21-48d...|    Wayne|   Hyman|139000|    2017|\n",
      "|business developm...|   Hobart|00019089-c2f9-48d...|    Linda|  Gardea| 83000|    2016|\n",
      "|medical radiation...|Melbourne|0001a9dc-3396-40e...|   Steven| Hilbert| 79000|    2018|\n",
      "|     counter manager|    Perth|0001da88-d735-4b9...|     Fred|Bernhard| 98000|    2015|\n",
      "|procurement speci...|Melbourne|0001f307-2457-4c6...|    Donna|    Kaps|107000|    2015|\n",
      "|    business analyst| Canberra|00021597-239e-47a...|   Robert| Garrett|113000|    2018|\n",
      "+--------------------+---------+--------------------+---------+--------+------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "storeDF = spark.sql(\"\"\" SELECT title, location, id, firstName, lastName, salary, SUBSTRING(fromDate, 1, 4) as yearMade  from (SELECT *, \n",
    "ROW_NUMBER() OVER(PARTITION BY id ORDER BY salary desc) AS row_number FROM people) where row_number = 1  \"\"\")\n",
    "storeDF.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db408068-aaa2-4ca4-b4c7-e140d9dfe4c2",
   "metadata": {},
   "source": [
    "17. write data into parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a22fbe4d-63e7-4192-8a6a-bcf21b33e171",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "storeDF.write.partitionBy(\"yearMade\")\\\n",
    "        .mode(\"overwrite\")\\\n",
    "        .option(\"compression\", \"snappy\")\\\n",
    "        .parquet(\"output/people\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4854212-b4c8-427a-a98e-56d151468dde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
